{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# What's Cooking Challenge\n",
    "\n",
    "### <i> Progetto per l'esame di Programmazione di applicazioni di Data Intensive (2019) </i>\n",
    "\n",
    "### Cichetti Federico, Sponziello Nicolò\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il progetto ha lo scopo di creare un modello in grado di classificare il tipo di cucina di una ricetta in base agli ingredienti forniti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esplorazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiamo caricando i dati in un dataframe Pandas e visualizzandone una parte per capire come sono strutturati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"train.json\")\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataframe ha tre colonne:\n",
    "- \"cuisine\" indica il tipo di cucina a cui appartiene il piatto. Questa sarà l'incognita da scoprire.\n",
    "- \"id\" è una colonna che contiene un numero identificativo di ogni piatto. Questo dato non è utile al problema, quindi decidiamo di eliminare la colonna e usare come identificativo l'indice aggiunto in automatico da Pandas.\n",
    "- \"ingredients\" contiene la lista di ingredienti del piatto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"id\" in df:\n",
    "    df.drop(\"id\", inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di procedere si esplorano e visualizzano alcuni dati, in particolare:\n",
    "* Quante ricette sono presenti\n",
    "* La totalità degli ingredienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le ricette da classificare nel dataset sono 39774 in totale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['cuisine'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In totale ci sono 20 tipi di cucine differenti. Si tratta quindi di un problema di classificazione multiclasse.\n",
    "Controlliamo quanti piatti ci sono per ogni cucina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cuisine'].value_counts().plot(\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal grafico possiamo notare che le classi sono sbilanciate, cioè sono presenti molte ricette che vengono identificate come cucina italiana e messicana, mentre ci sono poche ricette russe e brasiliane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################BILANCIAMENTO???????################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per analizzare gli ingredienti, per adesso usiamo un approccio iterativo. Si crea un set di ingredienti in modo da eliminare eventuali duplicati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = set()\n",
    "for recipe in df['ingredients']:\n",
    "    for i in recipe:\n",
    "        ingredients.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In totale notiamo che in tutto ci sono 6714 ingredienti diversi nel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo quelli più usati. Per fare questo gli ingredienti vanno inseriti in una lista in modo da mantenere i duplicati che poi dovranno essere contati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_list = list()\n",
    "for i in df['ingredients']:\n",
    "    for word in i:\n",
    "        ingredients_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ingredients = pd.Series(ingredients_list)\n",
    "common_ingredients.value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questi sono gli ingredienti più comuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ingredients.value_counts().nlargest(20).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo ora gli ingredienti più comuni per ogni cucina. Si crea un dizionario che contiene per ogni cucina un dizionario ingrediente -> numero di occorrenze e lo si ordina per tale conteggio. Possiamo poi costruire un DataFrame per visualizzare efficacemente quali sono gli ingredienti più usati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('cuisine')['ingredients'].apply(list)\n",
    "\n",
    "def most_common_ingr_by_cuisine(cuisine):\n",
    "    lists = tmp[cuisine]\n",
    "    res = defaultdict(int)\n",
    "    for recipe in lists:\n",
    "        for ingr in recipe:\n",
    "            res[ingr] += 1\n",
    "    return sorted(res.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamando la funzione qui sopra passando, ad esempio, la classe \"italian\" possiamo vedere che sale, olio di oliva, aglio e parmigiano sono alcuni degli ingredienti più comuni della cucina italiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "commons_ital = pd.DataFrame(most_common_ingr_by_cuisine('italian'), columns=[\"ingredient\", \"count\"]).head(10)\n",
    "commons_ital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In realtà il sale è l'ingrediente più comune per molte cucine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_common_ingr_by_cuisine('french'), columns=[\"ingredient\", \"count\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_common_ingr_by_cuisine('brazilian'), columns=[\"ingredient\", \"count\"]).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo ora una funzione che restituisca il numero di ingredienti medio per ogni ricetta di una determinata cucina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_ingr_per_recipe(cuisine):\n",
    "    recipes = tmp[cuisine]\n",
    "    count = 0;\n",
    "    for recipe in recipes:\n",
    "        for ingr in recipe:\n",
    "            count += 1;\n",
    "    return count/len(recipes)\n",
    "\n",
    "avg_ingr_per_recipe('brazilian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = {cuisine: avg_ingr_per_recipe(cuisine) for cuisine in df['cuisine'].unique()}\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 3))\n",
    "plt.bar(average.keys(), average.values(), align=\"center\", width=0.5)\n",
    "plt.title(\"Ingredienti medi per ricetta per ogni cucina\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa fase, con i risultati dell'analisi, effettuiamo la trasformazione dei dati per essere pronti per essere elaborati dagli algoritmi di learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come abbiamo potuto notare, il dataframe si compone di righe formate da:\n",
    "\n",
    "- **[cuisine]**: categoria di cucina\n",
    "- **[ingredients]**: lista di ingredienti in formato testuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo gestire gli ingredienti di una ricetta?\n",
    "\n",
    " - Considerandoli cosi come sono posti, cioè \"black olives\" rimane \"black olives\"\n",
    " - Unirli in un unica stringa e applicare tecniche di text processing per cercare di estrarre più informazioni\n",
    "   - Stemming, Lemming, Bag of Word, Vector Space Model (Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approccio iniziale che abbiamo provato, è stato quello di estrarre un set da tutti gli ingredienti presenti e binarizzare ogni ricetta presente\n",
    "    - Avremmo ottenuto un dataset con circa 6700 features e 40'000 istanze, con un'alta occupazione di memoria e lunghi calcoli CPU\n",
    "    - Per ogni riga, che rappresenta un recipe è associato un vettore in [0, 1] in cui la cella corrispondente all'ingrediente contiene\n",
    "    1 se è usato nella ricetta, 0 altrimenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si è rivelato però inefficiente e inaccurato, percui abbiamo scelto un approccio differente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approccio scelto è stato quello di utilizzare il modello tf-idf che si adatta particolarmente bene allo scopo\n",
    " - Tfidf associa ad ogni parola un peso che dipende sia dalla frequenza di uso locale Tf (cioè nella stessa ricetta) sia negli altri documenti idf (ricette)\n",
    " - Tutti gli ingredienti vengono mappati\n",
    " - I valori per ogni parola sono normalizzati in [0, 1]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inoltre permette di:\n",
    " - Eliminare eventuali stopword\n",
    " - Considerare sia singole parole, che ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa, manipoliamo la colonna 'ingredients' del dataframe\n",
    " - Da lista di ingredienti la trasformiamo in una unica stringa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df.index:\n",
    "    txt = \"\"\n",
    "    for ing in df.loc[idx, \"ingredients\"]:\n",
    "        txt += (ing + \" \")\n",
    "    df.loc[idx, \"ingredients\"] = txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo i set per il training dei modelli e il calcolo dello score sul validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(df['ingredients'], df['cuisine'], random_state=42, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniziamo lo studio dei modelli di classificazione dal più semplice, il Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"perc\", Perceptron())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottimizzare i parametri, usiamo la Grid Search\n",
    " - Testiamo anche quale ngram ottimizza lo score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = {\n",
    "    'tfidf__ngram_range':[(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    'perc__penalty': ['l1', 'l2']\n",
    "}\n",
    "gs_perc = GridSearchCV(perceptron, param_grid=grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_perc.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_perc.score(X_v, y_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
